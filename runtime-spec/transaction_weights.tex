\documentclass[11pt,a4paper]{article}
\usepackage{geometry}
\geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm,}
\usepackage{color}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{xargs}   % Use more than one optional parameter in new commands
\usepackage{xcolor}  % Coloured terxt etc.

\newtheorem{definition}{Definition}
\newcommand{\syed}[2]{{\underline{#1}}\textcolor{orange}{(#2)}}

\setlength\parindent{0pt}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\newcommand{\SubItem}[1]{
    {\setlength\itemindent{15pt} \item[-] #1}
}
\flushbottom

\newcommand{\TWF}{\ensuremath{\mathcal{W}}}
\SetKw{KwInit}{Init:} \SetKw{KwBy}{increment by} \SetKwProg{Fn}{Function}{
is}{end}

\begin{document}
\title{Polkadot Weights}
\author{Web3 Foundation}
\date{July 2020}
\maketitle

\section{Motivation}

The Polkadot network, like any other permissionless system, needs to implement a
mechanism to measure and to limit the usage in order to establish an economic
incentive structure, to prevent the network overload, and to mitigate DoS
vulnerabilities. In particular, Polkadot enforces a limited time-window for
block producers to create a block, including limitations on block size, which
can make the selection and execution of certain extrinsics too expensive and
decelerate the network.
\newline

In contrast to some other systems such as Ethereum which implement fine
measurement for each executed low-level operation by smart contracts, known as
gas metering, Polkadot takes a more relaxed approach by implementing a measuring
system where the cost of the transactions (referred to as 'extrinsics') are
determined before execution and are known as the weight system.

The Polkadot weight system introduces a mechanism for block producers to measure
the cost of running the extrinsics and determine how "heavy" it is in terms of
computational cost. Within this mechanism, block producers can select a set of
extrinsics and saturate the block to its fullest potential without exceeding any
limitations (as described in section \ref{sec:limitations}). Moreover, the
weight system can be used to calculate a fee for executing each extrinsics
according to its weight (as described in section \ref{sec:fee-calculation}).
\newline

Additionally, Polkadot introduces a specified block ratio (as defined in section
\ref{sec:limitations}), ensuring that only a certain portion of the total block
size gets used for regular extrinsics. The remaining space is reserved for
critical, operational extrinsics required for the functionality by Polkadot
itself.

To begin, we introduce in Section \ref{sec:assumptions} the assumption upon
which the Polkadot transaction weight system is designed. In Section
\ref{sec:limitations}, we discuss the limitation Polkadot needs to enforce on
the block size. In Section \ref{sec:runtime-primitives}, we describe in detail
the procedure upon which the weight of any transaction should be calculated. In
Section \ref{sec:practical-examples}, we present how we apply this procedure to
compute the weight of particular runtime functions.

\section{Assumptions}\label{sec:assumptions}

In this section, we define the concept of weight and we discuss the
considerations that need to be accounted for when assigning weight to
transactions. These considerations are essential in order for the weight system
to deliver its fundamental mission, i.e. the fair distribution of network
resources and preventing a network overload. In this regard, weights serve as an
indicator on whether a block is considered full and how much space is left for
remaining, pending extrinsics. Extrinsics which require too many resources are
discarded. More formally, the weight system should:

\begin{itemize}
\item prevent the block from being filled with too many extrinsics
\item avoid extrinsics where its execution takes too long, by assigning a
transaction fee to each extrinsic proportional to their resource consumption.
\end{itemize}

These concepts are formalized in Definitions \ref{def:block-length} and
\ref{def:polkadot-block-limits}:

\begin{definition}
  \label{def:block-length}
  For a block $B$ with $Head(B)$ and $Body(B)$ the {\b block length of $B$},
  $Len(B)$, is defined as the amount of raw bytes of $B$.
\end{definition}

\begin{definition}
  \label{def:target-time-per-block}
  {\b Targeted time per block} denoted by $T(B)$ \todo{TBD}.
\end{definition}

\begin{definition}
  \label{def:block-target-time}
  Available block ration reserved for normal, noted by $R(B)$, is defined as the
  maximum weight of none-operational transactions in the Body of $B$ divided by
  $Len(B)$.
\end{definition}

\begin{definition}
  \label{def:polkadot-block-limits}
        {\b Polkadot block limits} as defined here should be respected by each
        block producer for the produced block $B$ to be deemed valid:
        
        \begin{enumerate}
         \item $Len(B) \le 5 \times 1'024 \times 1'024 = 5'242'880$ Bytes
         \item $T(B) = 6\ seconds$
         \item $R(B) \le 0.75$
        \end{enumerate}
        
\end{definition}

\begin{definition}
  \label{defn:weight-function}
  The {\b Polkadot transaction weight function} denoted by $\mathcal{W}$ as follows:

  \begin{alignat*}{2}
    \mathcal{W} &: \mathcal{E} \rightarrow \mathbb{N} \\
    \mathcal{W} &: E \mapsto w
  \end{alignat*}

  where $w$ is a non-negative integer representing the weight of the extrinsic
  $E$. We define the weight of all inherent extrinsics as defined in
  \cite[Definition~3.3]{web30_technologies_foundation_polkadot_2020} to be equal
  to 0. we extend the definition of \TWF\ function to compute the weight of the
  block as sum of weight of all extrinsics its includes:

  \begin{alignat*}{2}
    \mathcal{W} &: \mathcal{B}\rightarrow \mathbb{N} \\
    \mathcal{W} &: B \mapsto \sum_{E\in B}(W(E))
  \end{alignat*}
  
\end{definition}

In the remainder of this section, we discuss the requirements to which the
weight function needs to comply to.

\begin{itemize}

\item Computations of function $\mathcal{W}(E)$  must be determined before
execution of that $E$.

\item Due to the limited time window, computations of $\TWF$ must be done
      quickly and consume few resources themselves.
\item $\TWF$ must be self contained and must not require I/O on the chain state.
$\TWF(E)$ must depend solely on the Runtime function representing $E$ and its
parameters.

\end{itemize}

Heuristically, "heaviness" corresponds to the resources consumption of an
extrinsic. In that way, the \TWF\ value for various extrinsics should be
proportional to their execution time and consumption of other system resources
such as memory and amount I/O operation. For example, if Extrinsic A takes three
times longer to execute than Extrinsic B while both Extrinsics consumes require
similar amount of memory and I/O operations, then Extrinsic A should roughly
weighs 3 times of Extrinsic B. Or

\[
\TWF(A)~3\times \TWF(B)
\]

Nonetheless, $\TWF(E)$ can be manipulated depending on the priority of $E$ the
chain is supposed to endorse.

\subsection{Limitations}\label{sec:limitations}

In this section we discuss how applying the limitation defined in Definition
\ref{def:polkadot-block-limits} can be translated to limitation $\TWF$. In order
to be able to translate those into concrete numbers, we need to identify an
arbitrary maximum weight to which we scale all other computations. For that we
first define the block weight and then assume a maximum on it block length in
Definition \ref{def:block-weight}:

\begin{definition}
  \label{def:block-weight} We define the {\b block weight} of block $B$,
  formally denoted as  $\TWF(B)$, to be:

  \[
    \TWF(B) = \sum^{|\mathcal{E}|}_{n = 0} (W(E_n))
  \]

  We require that:

  \[
    \TWF(B) < 2'000'000'000'000
  \]
\end{definition}

The weights must fulfil the requirements as noted by the fundamentals and
limitations, and can be assigned as the author sees fit. As a simple example,
consider a maximum block weight of 1'000'000'000, an available ratio of 75\% and
a targeted transaction throughput of 500 transactions, we could assign the
(average) weight for each transaction at about 1'500'000. Block producers have
economic incentive to include as many extrinsics as possible (without exceeding
limitations) into a block before reaching the targeted block time. Weights give
indicators to block producers on which extrinsics to include in order to reach
the blocks fullest potential.
\newline

\syed{Do note that the smallest, non-zero weight in Polkadot is set at 10'000.}{why do we need this, we need to justify having a minimum}

\section{Calculation of the weight function}
\label{sec:runtime-primitives}
In order to calculate weight of block $B$, $TWF(B)$, one needs to evaluate the
weight of each transaction included in the block. Each transaction causes the
execution certain Runtime functions. As such, to calculate the weight of a
transaction, those functions must be analyzed in order to determine parts of the
code which can significantly contribute to the execution time and consume
resources such as  loops, I/O operations, and data manipulation. Subsequently
the performance and resource consumption of each part will be evaluated based on
variety of input parameters. Based on those observations, weights are assigned
Runtime functions or parameters which contribute to heavy resource consumption.
These sub component of the code are discussed in Section
\ref{sect:primitive-types}.
\newline

The general algorithm to calculate $\TWF(E)$ is described in the Section
\ref{sect:benchmarking}.
\newline

\syed{The final assigned weights are calculated by benchmarking the Runtime
functions, which is described in section \ref{sect:benchmarking}.}{this needs to
relate the computation of final weight to the primitive otherwise the paragraph
looks disconnected}.
\newline

Section \ref{sec:practical-examples} walks through two practical examples of
Runtime function analysis.

\section{Benchmarking}\label{sect:benchmarking} Calculating the extrinsic weight
solely based on theoretical complexity of the underlying implementation proves
to be too complicated and unreliable at the same time. Certain decisions in the
source code architecture, internal communication within the Runtime or other
design choices could add enough overhead to make the asymptotic complexity
practically meaningless.
\newline

On the other hand, benchmarking an extrinsics in a black-box fashion could
(using random parameters) most centainly results in missing corner cases and
worst case senarios. Instead, we benchmark all available Runtime functions which
are invoked in the course of execution of extrinsics with a large collection of
carefully selected input parameters and use the result of the benchmarking
process to evaluate $\TWF(E)$.
\newline

In order to select useful parameters, the Runtime functions have to be analysed
to fully understand which behaviors or conditions can result in expensive
execution times, which is described closer in section
\ref{sect:primitive-types}.

\todo{review after reading the examples} Not every possible benchmarking outcome
can be invoked by varying input parameters of the Runtime function. In some
circumstances, preliminary work is required before a specific benchmark can be
reliably measured, such as creating certain preexisting entries in the storage
or other changes to the environment. This is explained in more detail in section
\ref{sect:examples-preliminary-work}.
\newpage

\subsection{Primitive Types}\label{sect:primitive-types}
The Runtime reuses components, known as "primitives", to interact with the state
storage. The execution cost of those primitives can be measured and a weight
should be applied for each occurrence within the Runtime code.
\newline

For storage, Polkadot uses three different types of storage types across its
modules, depending on the context:

\begin{itemize}
  \item \textbf{Value}: Operations on a single value. \newline\newline
  The final key-value pair is stored under the key:\newline
  \begin{verbatim}
    hash(module_prefix) + hash(storage_prefix)
  \end{verbatim}
  \item \textbf{Map}: Operations on mulitple values, datasets, where each entry
  has its corresponding, unique key. \newline\newline
  The final key-value pair is stored under the key:\newline
  \begin{verbatim}
    hash(module_prefix) + hash(storage_prefix) + hash(encode(key))
  \end{verbatim}
  \item \textbf{Double map}: Just like \textbf{Map}, but uses two keys instead
  of one. This type is also known as "child storage", where the first key is the
  "parent key" and the second key is the "child key". This is useful in order to
  scope storage entries (child keys) under a certain \verb|context| (parent
  key), which is arbitrary. Therefore, one can have separated storage entries
  based on the context.
  \newline\newline
  The final key-value pair is stored under the key:\newline
  \begin{verbatim}
    hash(module_prefix) + hash(storage_prefix)
      + hash(encode(key1)) + hash(encode(key2))
  \end{verbatim}
\end{itemize}

It depends on the functionality of the Runtime module (or its sub-processes,
rather) which storage type to use. In some cases, only a single value is
required. In others, multiple values need to be fetched or inserted from/into
the database.
\newline

Those lower level types get abstracted over in each individual Runtime module
using the \verb|decl_storage!| macro. Therefore, each module specifies its own
types that are used as input and output values. The abstractions do give
indicators on what operations must be closely observed and where potential
performance penalties and attack vectors are possible.

\subsubsection{Considerations}\label{sect:primitive-types-considerations}

The storage layout is mostly the same for every primitive type, primarily
differentiated by using special prefixes for the storage key. Big differences
arise on how the primitive types are used in the Runtime function, on whether
single values or entire datasets are being worked on. Single value operations
are generally quite cheap and its execution time does not vary depending on the
data that's being processed. However, excessive overhead can appear when I/O
operations are executed repeatedly, such as in loops. Especially, when the amount
of loop iterations can be influenced by the caller of the function or by certain
conditions in the state storage.
\newline

Maps, in contrast, have additional overhead when inserting or retrieving
datasets, which vary in sizes. Additionally, the Runtime function has to process
each item inside that list.
\newline

Indicators for performance penalties:

\begin{itemize}
  \item \textbf{Fixed iterations and datasets} - Fixed iterations and datasets
  can increase the overall cost of the Runtime functions, but the execution time
  does not vary depending on the input parameters or storage entries. A base
  Weight is appropriate in this case.
  \item \textbf{Adjustable iterations and datasets} - If the amount of
  iterations or datasets depend on the input parameters of the caller or
  specific entries in storage, then a certain weight should be applied for each
  (additional) iteration or item. The Runtime defines the maximum value for such
  cases. If it doesn't, it unconditionally has to and the Runtime module must be
  adjusted. \newline\newline
  When selecting parameters for benchmarking, the benchmarks should range from
  the minimum value to the maximum value, as described in paragraph
  \ref{para:max-value}.
  \item \textbf{Input parameters} - Input parameters that users pass on to the
  Runtime function can result in expensive operations. Depending on the data
  type, it can be appropriate to add additional weights based on certain
  properties, such as data size, assuming the data type allows varying sizes.
  The Runtime must define limits on those properties. If it doesn't, it
  unconditionally has to and the Runtime module must be adjusted.
  \newline\newline
  When selecting parameters for benchmarking, the benchmarks should range from
  the minimum values to the maximum value, as described in paragraph
  \ref{para:max-value}.
\end{itemize}

\label{para:max-value} What the maximum value should be really depends on the
functionality that the Runtime function is trying to provide. If the choice for
that value is not obvious, then it's advised to run benchmarks on a big range of
values and pick a conservative value below the \verb|targeted time per block|
limit as described in section \ref{sec:limitations}.

\subsection{Parameters}
The inputs parameters highly vary depending on the Runtime function and must
therefore be carefully selected. The benchmarks should use input parameters
which will most likely be used in regular cases, as intended by the authors, but
must also consider worst case scenarios and inputs which might decelerate or
heavily impact performance of the function. The input parameters should be
randomised in order to cause various effects in behaviors on certain values,
such as memory relocations and other outcomes that can impact performance.
\newline

It's not possible to benchmark every single value. However, one should select a
range of inputs to benchmark, spanning from the minimum value to the maximum
value which will most likely exceed the expected usage of that function. This is
described in more detail in section \ref{sect:primitive-types-considerations}.
\newline

The benchmarks should run individual executions/iterations within that range,
where the chosen parameters should give insight on the execution time and
resource cost. Selecting imprecise parameters or too extreme ranges might
indicate an inaccurate result of the function as it will be used in production.
Therefore, when a range of input parameters gets benchmarked, the result of each
individual parameter should be recorded and ideally visualized. The author
should then decide on the most probable average execution time, basing that
decision on the limitations of the Runtime and expected usage of the network.
\newline

Additionally, given the distinction theoretical and practical usage, the author
reserves the right to make adjustments to the input parameters and assigned
weights according to observed behavior of the actual, real-world network.

\subsection{Blockchain State}
The benchmarks should be performed on blockchain states that already polluted
and contain a history of extrinsics and storage changes. Runtime functions that
require I/O on structures such as Tries will therefore produce more realistic
results that will reflect the real-world performance of the Runtime.

\subsection{Environment}
The benchmarks should be executed on clean systems without interference of other
processes or software. Additionally, the benchmarks should be executed on
multiple machines with different system resources, such as CPU performance, CPU
cores, RAM and storage speed.

\section{Practical examples}\label{sec:practical-examples}

\subsection{Runtime function analysis}

This section walks through Runtime functions available in the Polkadot Runtime
to demonstrate the analysis process as described in section
\ref{sect:primitive-types}.

\subsubsection{Practical example \#1}

\subsubsection*{Analysis}

In Polkadot, accounts can save information about themselves onchain, known as
the "Identity Info". This includes information such as display name, legal name,
email address and so on. Polkadot selects a set of registrars, entities elected
by the Polkadot public referendum, which can judge identities and therefore
incentivizes a reputation model. The judgement itself is done offchain. The
registrars rating, however, is saved onchain, directly in the corresponding
Identity Info. It's also note worthy that Identiy Info can contain additional
fields, set manually by the corresponding account holder.
\newline

The function \verb|request_judgement| from the \verb|identity| pallet allows
users to request judgement from a specific registrar. If this function is called
by a previously judged user it implies that the Identity Info should be
rejudged. Studying this function reveals multiple design choices that can impact
performance, as it will be revealed by this analysis.
\newline

First, it fetches a list of current registrars from storage and then searches
that list for the specified registrar index.

\begin{verbatim}
let registrars = <Registrars<T>>::get();
let registrar = registrars.get(reg_index as usize).and_then(Option::as_ref)
  .ok_or(Error::<T>::EmptyIndex)?;
\end{verbatim}

Then, it searches for the Identity Info from storage, based on the sender of the
transaction.

\begin{verbatim}
let mut id = <IdentityOf<T>>::get(&sender).ok_or(Error::<T>::NoIdentity)?;
\end{verbatim}

The Identity Info contains all fields that have a value set, in an ordered form.
It then proceeds to search all those entries for the specified registrar index.
If the entry can be found, the corresponding value is updated to the value
passed on as the function parameters (assuming the registrar is not "stickied",
which implies it cannot be changed). If the entry cannot be found, the value is
inserted into the index where a matching element can be inserted while
maintaining sorted order. This results in memory reallocation.

\begin{verbatim}
match id.judgements.binary_search_by_key(&reg_index, |x| x.0) {
  Ok(i) => if id.judgements[i].1.is_sticky() {
    Err(Error::<T>::StickyJudgement)?
  } else {
    id.judgements[i] = item
  },
  Err(i) => id.judgements.insert(i, item),
}
\end{verbatim}

In the end, the function ensures that the sender of the extrinsic has the
required balance in order to pay the fee, a balance that is adjustable and
determined by the Runtime itself. Then, an event is created to insert the
Identity Info into storage. The creation of events is lightweight, but its
execution is what will actually commit the state changes.

\begin{verbatim}
T::Currency::reserve(&sender, registrar.fee)?;
<IdentityOf<T>>::insert(&sender, id);
Self::deposit_event(RawEvent::JudgementRequested(sender, reg_index));
\end{verbatim}

\subsubsection*{Considerations}

Based on the considerations described in section
\ref{sect:primitive-types-considerations}, the analysis reveals multiple,
critical points. Those must be covered in the benchmarking processes described
in section \ref{sect:benchmarking} and require preliminary work as described in
section \ref{sect:examples-preliminary-work}.
\newline

Key points:
\begin{itemize}
  \item Varying amount of registrars.
  \item Varying amount of preexisting accounts in storage.
  \item The specified registrar is searched for in the Identity Info.
  Additionally, if a new value gets inserted into the byte array, memory get
  reallocated. Depending on the size of the Identity Info, the execution time
  can vary.
  \item Varying sizes of Identity Info, including additional fields.
  \item It is legitimate to introduce additional weights for changes the sender
  has influence over, such the additional fields in the Identity Info.
\end{itemize}

\subsubsection{Preliminary Work}

The Polkadot Runtime specifies the \verb|MaxRegistrars| constant, which will
prevent the list of registrars of reaching an undesired length. This value
should have some influence on the benchmarking process.
\newline

The benchmarking implementation of for the function $request\_judgement$ can be
defined as follows:

\begin{algorithm}[H]
  \caption{Run multiple benchmark iterations for $request\_judgement$ Runtime function}
  \SetAlgoLined
  \KwResult{\textit{collection:} a collection of time measurements of all
  benchmark iterations}
  \BlankLine
  \Fn{\textsc{Main}}{
    \KwInit{collection = \{\};}\\
    \textsc{Pollute-Storage;}\\
    \For{$amount \leftarrow 1$ \KwTo $MaxRegistrars$ \KwBy $1$}{
      \textsc{Generate-Registrars($amount$)};\\
      $caller \leftarrow$ \textsc{Create-Account("caller", $1$)};\\
      \textsc{Set-Balance($caller$, 100)};\\
      $time \leftarrow$ \textsc{Timer(Request-Judgement(Random($amount$), 100))};\\
      \textsc{Add-To($collection$, $time$)};
    }
    \Return{$collection$}
  }
\end{algorithm}

\begin{itemize}
  \item \textsc{Generate-Registrars($amount$)}
  \SubItem{Creates $amount$ of registrars and inserts those records into storage.}
  \item \textsc{Create-Account($name$, $index$)} \SubItem{Creates a Blake2 hash
      of the concatenated input of $name$ and $index$ representing the address
      of a account. This function only creates an address and does not conduct
      any I/O.}
  \item \textsc{Set-Balance($account$, $balance$)}
  \SubItem{Sets a initial $balance$ for the specified $account$ in the storage state.}
  \item \textsc{Timer($function$)}
  \SubItem{Measures the time from the start of the specified $function$ to its completion.}
  \item \textsc{Request-Judgement($registrar\_index$, $max\_fee$)}
  \SubItem{Calls the corresponding $request\_judgement$ Runtime function and passes on
  the required parameters.}
  \item \textsc{Random($num$)}
  \SubItem{Picks a random number between 0 and $num$. This should be used when the benchmark
  should account for unpredictable values.}
  \item \textsc{Add-To($collection$, $time$)}
  \SubItem{Adds a returned time measurement ($time$) to $collection$.}
\end{itemize}

\subsubsection{Practical example \#2}

\subsubsection*{Analysis}

The function \verb|payout_stakers| from the \verb|staking| Pallet can be called
by a single account in order to payout the reward for all nominators who back a
particular validator. The reward also covers the validator's share. This
function is interesting because it iterators over a range of nominators, which
varies, and does I/O operation for each of them.
\newline

First, this function makes some basic checks to verify if the specified era is
not higher then the current era (future) and is within the allowed range
("history depth"), specified by the Runtime. After that, it fetches the era
payout from storage and additionally verifies whether the specified account is
indeed a validator and receives the corresponding "Ledger".

\begin{verbatim}
let era_payout = <ErasValidatorReward<T>>::get(&era)
  .ok_or_else(|| Error::<T>::InvalidEraToReward)?;

let controller = Self::bonded(&validator_stash).ok_or(Error::<T>::NotStash)?;
let mut ledger = <Ledger<T>>::get(&controller).ok_or_else(|| Error::<T>::NotController)?;
\end{verbatim}

The Ledger keeps a list of tracked rewards. The function only retains the
entries of the "history depth", and conducts a binary search for the specified
era.

\begin{verbatim}
ledger.claimed_rewards.retain(|&x| x >= current_era.saturating_sub(history_depth));
match ledger.claimed_rewards.binary_search(&era) {
  Ok(_) => Err(Error::<T>::AlreadyClaimed)?,
  Err(pos) => ledger.claimed_rewards.insert(pos, era),
}
\end{verbatim}

The retained claimed rewards are inserted back into storage.

\begin{verbatim}
<Ledger<T>>::insert(&controller, &ledger);
\end{verbatim}

The Runtime is actually optimized to some degree: it only fetches a list of the
highest staked nominators, a maximum of 64. The rest gets no reward.

\begin{verbatim}
let exposure = <ErasStakersClipped<T>>::get(&era, &ledger.stash);
\end{verbatim}

Next, the function gets the era reward points from storage.

\begin{verbatim}
let era_reward_points = <ErasRewardPoints<T>>::get(&era);
\end{verbatim}

After that, the payout is split among the validator and its nominators. The
validators receives the payment first, creating an insertion into storage and
sending a deposit event to the scheduler.

\begin{verbatim}
if let Some(imbalance) = Self::make_payout(
  &ledger.stash,
  validator_staking_payout + validator_commission_payout
) {
  Self::deposit_event(RawEvent::Reward(ledger.stash, imbalance.peek()));
}
\end{verbatim}

Then, the nominators receive a payout. The functions loops through the nominator
list, conducting a insertion into storage and a creation of a deposit event for
each of the nominators.

\begin{verbatim}
for nominator in exposure.others.iter() {
  let nominator_exposure_part = Perbill::from_rational_approximation(
    nominator.value,
    exposure.total,
  );

  let nominator_reward: BalanceOf<T> = nominator_exposure_part * validator_leftover_payout;
  // We can now make nominator payout:
  if let Some(imbalance) = Self::make_payout(&nominator.who, nominator_reward) {
    Self::deposit_event(RawEvent::Reward(nominator.who.clone(), imbalance.peek()));
  }
}
\end{verbatim}

\subsubsection*{Considerations}

Based on the considerations described in section
\ref{sect:primitive-types-considerations}, the analysis reveals multiple,
critical points. Those must be covered in the benchmarking processes described
in section \ref{sect:benchmarking} and require preliminary work as described in
section \ref{sect:examples-preliminary-work}.
\newline

Key points:

\begin{itemize}
  \item The Ledger contains a varying list of claimed rewards. Fetching,
  retaining and searching through it can affect execution time. The retained
  list is inserted back into storage.
  \item Looping through a list of nominators and creating I/O operations for
  each increases execution time. The Runtime fetches up to 64 nominators.
\end{itemize}

\subsubsection{Preliminary Work}

The Polkadot Runtime defines the \verb|HistoryDepth| constant, which dictates
the amount of Eras the reward system takes under consideration. Additionally,
the constant \verb|MaxNominatorRewardedPerValidator| specifies the maximum
amount of the highest-staked nominators which will get a reward. Those values
should have some influence in the benchmarking process.
\newline

The benchmarking implementation for the function $payout\_stakers$ can be
defined as follows:
\newline

\begin{algorithm}[H]
  \caption{Run multiple benchmark iterations for $payout\_stakers$ Runtime function}
  \SetAlgoLined
  \KwResult{\textit{collection:} a collection of time measurements of all
  benchmark iterations}
  \BlankLine
  \Fn{\textsc{Main}}{
    \KwInit{collection = \{\};}\\
    \textsc{Pollute-Storage()};\\
    \For{$amount \leftarrow 1$ \KwTo $MaxNominatorRewardedPerValidator$ \KwBy $1$}{
      \For{$era\_depth \leftarrow 1$ \KwTo $HistoryDepth$ \KwBy $1$}{
        $validator \leftarrow$ \textsc{Generate-Validator()};\\
        \textsc{Validate($validator$)};\\
        $nominators \leftarrow$ \textsc{Generate-Nominators($amount$)};\\
        \For{$nominator \in nominators$}{
          \textsc{Nominate($validator$, $nominator$)}
        }
        $era\_index \leftarrow$ \textsc{Create-Rewards($validator$, $nominators$, $era\_depth$)};\\
        $time \leftarrow$ \textsc{Timer(Payout-Stakers($validator$), $era\_index$))};\\
        \textsc{Add-To($collection$, $time$)};
      }
    }
    \Return{$collection$}
  }
\end{algorithm}

\begin{itemize}
  \item \textsc{Generate-Validator()}
  \SubItem{Creates a validators with some unbonded balances.}
  \item \textsc{Validate($validator$)}
  \SubItem{Bonds balances of $validator$ and bonds balances.}
  \item \textsc{Generate-Nominators($amount$)}
  \SubItem{Creates the $amount$ of nominators with some unbonded balances.}
  \item \textsc{Nominate($validator$, $nominator$)}
  \SubItem{Starts nomination of $nominator$ for $validator$ by bonding balances.}
  \item \textsc{Create-Rewards($validator$, $nominators$, $era\_depth$)}
  \SubItem{Starts an Era and creates pending rewards for $validator$ and $nominators$}
  \item \textsc{Timer($function$)} \SubItem{Measures the time from the start of
      the specified $function$ to its completion.}
  \item \textsc{Add-To($collection$, $time$)} \SubItem{Adds a returned time
      measurement ($time$) to $collection$.}
\end{itemize}

\subsection{Preliminary Work}\label{sect:examples-preliminary-work}
In order for certain benchmarks to produce conditions where resource heavy
computation or excessive I/O can be observed, the benchmarks might require some
preliminary work on the environment, since those conditions cannot be created
with simply selected parameters. As practical examples, this section describes
the specifically designed benchmarks for the \verb|transfer| and
\verb|withdraw_unbonded| functions available in the Polkadot Runtime.

\subsubsection{Practical example \#1}
The $transfer$ function of the \textit{balances} module is designed to move the
specified balance by the sender to the receiver. The benchmark is configured to
measure the function's worst possible condition:

\begin{itemize}
  \item Transfer will kill the sender account (by completely depleting the
  balance to zero).
  \item Transfer will create the recipient account (the recipient account
  doesn't have a balance yet).
\end{itemize}

\subsubsection*{Parameters}
The following parameters are selected:

\begin{center}
  \begin{tabular}{ l|r l l l }
    \textbf{Type} && \textbf{From} & \textbf{To} & \textbf{Description}\\
    \hline
    Account index & \verb|index| in... & 1 & 1000 & Used as a seed for account
    creation \\
    Balance & \verb|balance| in... & 2 & 1000 & Sender balance and transfer
    amount \\
  \end{tabular}
\end{center}

Executing a benchmark for each balance increment within the balance range for
each index increment within the index range will generate too many variants
($1000 \times 999$) and highly increase execution time. Therefore, this
benchmark is configured to first set the balance at value 1'000 and then to
iterate from 1 to 1'000 for the index value. Once the index value reaches 1'000,
the balance value will reset to 2 and iterate to 1'000 (see algorithm
\ref{sec:algo-benchmark-transfer} for more detail):

\begin{itemize}
  \item \verb|index|: 1, \verb|balance|: 1000
  \item \verb|index|: 2, \verb|balance|: 1000
  \item \verb|index|: 3, \verb|balance|: 1000
  \item ...
  \item \verb|index|: 1000, \verb|balance|: 1000
  \item \verb|index|: 1000, \verb|balance|: 2
  \item \verb|index|: 1000, \verb|balance|: 3
  \item \verb|index|: 1000, \verb|balance|: 4
  \item ...
\end{itemize}

The parameters itself do not influence or trigger the two worst conditions and
must be handled by the implemented benchmarking tool. The $transfer$ benchmark
is implemented as defined in algorithm \ref{sec:algo-benchmark-transfer}.

\subsubsection*{Implementation}
The benchmarking implementation for the Polkadot Runtime function $transfer$ is
defined as follows (starting with the \textsc{Main} function):
\newline

\begin{algorithm}[H]\label{sec:algo-benchmark-transfer}
  \caption{Run multiple benchmark iterations for $transfer$ Runtime function}
  \SetAlgoLined \KwResult{$collection$: a collection of time measurements of all
  benchmark iterations} \BlankLine \Fn{\textsc{Main}}{\KwInit{collection =
  \{\}\;} \KwInit{$balance = 1'000$\;} \For{$index\gets1$ \KwTo $1'000$ \KwBy
  $1$}{$time \leftarrow$ \textsc{Run-Benchmark($index$, $balance$)}\;
  \textsc{Add-To($collection$, $time$)}\;} \BlankLine \KwInit{$index = 1'000$\;}
  \For{$balance\gets2$ \KwTo $1'000$ \KwBy $1$}{$time \leftarrow$
  \textsc{Run-Benchmark($index$, $balance$)}\; \textsc{Add-To($collection$,
  $time$)}\;}} \BlankLine \Fn{\textsc{Run-Benchmark($index$,
  $balance$)}}{$sender \leftarrow$ \textsc{Create-Account(\textit{"caller"},
  $index$)}\; $recipient \leftarrow$
  \textsc{Create-Account(\textit{"recipient"}, $index$)}\;
  \textsc{Set-Balance($sender$, $balance$)}\; \BlankLine $time
  \leftarrow$\textsc{Timer(Transfer($sender$, $recipient$, $balance$))}\;
  \Return $time$}
\end{algorithm}

\begin{itemize}
  \item \textsc{Create-Account($name$, $index$)} \SubItem{Creates a Blake2 hash
      of the concatenated input of $name$ and $index$ representing the address
      of a account. This function only creates an address and does not conduct
      any I/O.}
  \item \textsc{Set-Balance($account$, $balance$)} \SubItem{Sets a initial
      $balance$ for the specified $account$ in the storage state.}
  \item \textsc{Transfer($sender$, $recipient$, $balance$)} \SubItem{Transfers
      the specified $balance$ from $sender$ to $recipient$ by calling the
      corresponding Runtime function. This represents the target Runtime
      function to be benchmarked.}
  \item \textsc{Add-To($collection$, $time$)} \SubItem{Adds a returned time
      measurement ($time$) to $collection$.}
  \item \textsc{Timer($function$)} \SubItem{Measures the time from the start of
      the specified $function$ to its completion.}
\end{itemize}

\subsubsection{Practical example \#2}
The $withdraw\_unbonded$ function of the \textit{staking} module is designed to
move any unlocked funds from the staking management system to be ready for
transfer. The benchmark requires a couple of I/O operations:

\begin{itemize}
  \item Create stash account and set initial balance.
  \item Create controller account and set initial balance.
  \item Bond a certain amount of the funds.
  \item Unbond full amount of the funds.
  \item Withdraw unbonded amount, making it ready for transfer.
\end{itemize}

\subsubsection*{Parameters}
The following parameters are selected:

\begin{center}
  \begin{tabular}{ l|r l l l }
    \textbf{Type} && \textbf{From} & \textbf{To} & \textbf{Description}\\
    \hline
    Account index & \verb|index| in... & 0 & 1000 & Used as a seed for account
    creation \\
  \end{tabular}
\end{center}

This benchmark does not require complex parameters. The values is use solely for
account generation.

\subsubsection*{Implementation}
The benchmarking implementation for the Polkadot Runtime function
$withdraw\_unbonded$ is defined as follows:
\newline

\begin{algorithm}[H]\label{sec:algo-benchmark-transfer}
  \caption{Run multiple benchmark iterations for $withdraw_unbonded$ Runtime function}
  \SetAlgoLined \KwResult{$collection$: a collection of time measurements of all
  benchmark iterations} \BlankLine \Fn{\textsc{Main}}{\KwInit{collection =
  \{\}\;} \For{$index\gets0$ \KwTo $1'000$ \KwBy $1$}{$stash \leftarrow$
  \textsc{Create-Account(\textit{"stash"}, $index$)}\; $controller \leftarrow$
  \textsc{Create-Account(\textit{"controller"}, $index$)}\;
  \textsc{Set-Balance($stash$, 100)}\; \textsc{Set-Balance($controller$, 100)}\;
  \textsc{Bond($stash$, $controller$, 10)}\; \textsc{UnBond($controller$, 10)}\;
  $time \leftarrow$\textsc{Timer(Withdraw-Unbonded($controller$))}\;
  \textsc{Add-To($collection$, $time$)}\;}} \BlankLine
\end{algorithm}

\begin{itemize}
  \item \textsc{Create-Account($name$, $index$)} \SubItem{Creates a Blake2 hash
    of the concatenated input of $name$ and $index$ representing the address of
    a account. This function only creates an address and does not conduct any
    I/O.}
  \item \textsc{Set-Balance($account$, $balance$)} \SubItem{Sets a initial
      $balance$ for the specified $account$ in the storage state.}
  \item \textsc{Bond($stash$, $controller$, $amount$)} \SubItem{Bonds the
    specified $amount$ for the $stash$ and $controller$ pair.}
  \item \textsc{UnBond($account$, $amount$)} \SubItem{Unbonds the specified
    $amount$ for the given $account$.}
  \item \textsc{Withdraw-Unbonded($controller$)} \SubItem{Withdraws the the full
    unbonded amount of the specified $controller$ account. This represents the
    target Runtime function to be benchmarked}
  \item \textsc{Add-To($collection$, $time$)} \SubItem{Adds a returned time
    measurement ($time$) to $collection$.}
  \item \textsc{Timer($function$)} \SubItem{Measures the time from the start of
    the specified $function$ to its completion.}
\end{itemize}

\section{Fees}
Block producers charge a fee in order to be economically sustainable. That fee
must always be covered by the sender of the transaction. Polkadot has a flexible
mechanism to determine the minimum cost to include transactions in a block.

\subsection{Fee Calculation}\label{sec:fee-calculation}
Polkadot fees consists of three parts:

\begin{itemize}
\item Base fee: a fixed fee that is applied to every transaction and set by the
Runtime.
\item Length fee: a fee that gets multiplied by the length of the transaction,
in bytes.
\item Weight fee: a fee for each, varying Runtime function. Runtime implementers
      need to implement a conversion mechanism which determines the
      corresponding currency amount for the calculated weight.
\end{itemize}

The final fee can be summarized as:
\begin{eqnarray*}
\lefteqn{fee = base\ fee}\\
      &&{} + length\ of\ transaction\ in\ bytes \times length\ fee\\
      &&{} + weight\ to\ fee\\
\end{eqnarray*}

\subsection{Definitions in Polkadot}
The Polkadot Runtime defines the following values:
\begin{itemize}
\item Base fee: 100 uDOTs
\item Length fee: 0.1 uDOTs
\item Weight to fee conversion:
      $$
            weight\ fee = weight \times (100\ uDOTs \div (10 \times 10'000))
      $$
      A weight of 10'000 (the smallest non-zero weight) is mapped to
      $\frac{1}{10}$ of 100 uDOT.
      \newline
      This fee will never exceed the max size of an unsigned 128 bit integer.
\end{itemize}

\subsection{Fee Multiplier}
Polkadot can add a additional fee to transactions if the network becomes too
busy and starts to decelerate the system. This fees can create incentive to
avoid the production of low priority or insignificant transactions. In contrast,
those additional fees will decrease if the network calms down and it can execute
transactions without much difficulties.
\newline

That additional fee is known as the \verb|Fee Multiplier| and its value is
defined by the Polkadot Runtime. The multiplier works by comparing the
saturation of blocks; if the previous block is less saturated than the current
block (implying an uptrend), the fee is slightly increased. Similarly, if the
previous block is more saturated than the current block (implying a downtrend),
the fee is slightly decreased.
\newline

The final fee is calculated as:
$$
      final\ fee = fee \times Fee\ Multiplier
$$

\subsubsection{Update Multiplier}
The \verb|Update Multiplier| defines how the multiplier can change. The Polkadot
Runtime internally updates the multiplier after each block according the
following formula:

\begin{eqnarray*}
diff &=& (target\ weight - previous\ block\ weight)\\
v &=& 0.00004\\
next\ weight &=& weight \times (1 + (v \times diff) + (v \times diff)^2 / 2)\\
\end{eqnarray*}

Polkadot defines the \verb|target_weight| as 0.25 (25\%). More information about
this algorithm is described in the Web3 Foundation research paper:
\url{https://research.web3.foundation/en/latest/polkadot/Token%20Economics.html#relay-chain-transaction-fees-and-per-block-transaction-limits}.

\end{document}
