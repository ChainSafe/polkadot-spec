\chapter{Implementer's Guide}

\section{Ramble / Preamble}

This document aims to describe the purpose, functionality, and implementation of
a host for Polkadot's parachains. It is not for the implementor of a specific
parachain but rather for the implementor of the Parachain Host, which provides
security and advancement for constituent parachains. In practice, this is for
the implementors of Polkadot.
\newline

There are a number of other documents describing the research in more detail.
All referenced documents will be linked here and should be read alongside this
document for the best understanding of the full picture. However, this is the
only document which aims to describe key aspects of Polkadot's particular
instantiation of much of that research down to low-level technical details and
software architecture.

\section{Origins}

Parachains are the solution to a problem. As with any solution, it cannot be
understood without first understanding the problem. So let's start by going over
the issues faced by blockchain technology that led to us beginning to explore
the design space for something like parachains.

\subsection{Issue 1: Scalability}

It became clear a few years ago that the transaction throughput of simple
Proof-of-Work (PoW) blockchains such as Bitcoin, Ethereum, and myriad others was
simply too low. \todo{PoS, sharding, what if there were more blockchains, etc.
etc.}
\newline

Proof-of-Stake (PoS) systems can accomplish higher throughput than PoW
blockchains. PoS systems are secured by bonded capital as opposed to spent
effort - liquidity opportunity cost vs. burning electricity. The way they work
is by selecting a set of validators with known economic identity who lock up
tokens in exchange for earning the right to "validate" or participate in the
consensus process. If they are found to carry out that process wrongly, they
will be slashed, meaning some or all of the locked tokens will be burned. This
provides a strong disincentive in the direction of misbehavior.
\newline

Since the consensus protocol doesn't revolve around wasting effort, block times
and agreement can occur much faster. Solutions to PoW challenges don't have to
be found before a block can be authored, so the overhead of authoring a block is
reduced to only the costs of creating and distributing the block.
\newline

However, consensus on a PoS chain requires full agreement of 2/3+ of the
validator set for everything that occurs at Layer 1: all logic which is carried
out as part of the blockchain's state machine. This means that everybody still
needs to check everything. Furthermore, validators may have different views of
the system based on the information that they receive over an asynchronous
network, making agreement on the latest state more difficult.
\newline

Parachains are an example of a \textbf{sharded} protocol. Sharding is a concept
borrowed from traditional database architecture. Rather than requiring every
participant to check every transaction, we require each participant to check
some subset of transactions, with enough redundancy baked in that byzantine
(arbitrarily malicious) participants can't sneak in invalid transactions - at
least not without being detected and getting slashed, with those transactions
reverted.
\newline

Sharding and Proof-of-Stake in coordination with each other allow a parachain
host to provide full security on many parachains, even without all participants
checking all state transitions.

\todo{note about network effects \& bridging}

\subsection{Issue 2: Flexibility / Specialization}

"dumb" VMs don't give you the flexibility. Any engineer knows that being able to
specialize on a problem gives them and their users more leverage. \todo{...}
\newline

Having recognized these issues, we set out to find a solution to these problems,
which could allow developers to create and deploy purpose-built blockchains
unified under a common source of security, with the capability of
message-passing between them; a heterogeneous sharding solution, which we have
come to know as \textbf{Parachains}.

\section{Parachains: Basic Functionality}

This section aims to describe, at a high level, the architecture, actors, and
Subsystems involved in the implementation of parachains. It also illuminates
certain subtleties and challenges faced in the design and implementation of
those Subsystems. Our goal is to carry a parachain block from authoring to
secure inclusion, and define a process which can be carried out repeatedly and
in parallel for many different parachains to extend them over time.
Understanding of the high-level approach taken here is important to provide
context for the proposed architecture further on.
\newline

The Parachain Host is a blockchain, known as the relay-chain, and the actors
which provide security and inputs to the blockchain.
\newline

First, it's important to go over the main actors we have involved in the
parachain host.
\newline

\begin{enumerate}
    \item Validators. These nodes are responsible for validating proposed
    parachain blocks. They do so by checking a Proof-of-Validity (PoV) of the
    block and ensuring that the PoV remains available. They put financial
    capital down as "skin in the game" which can be slashed (destroyed) if they
    are proven to have misvalidated.
    \item Collators. These nodes are responsible for creating the
    Proofs-of-Validity that validators know how to check. Creating a PoV
    typically requires familiarity with the transaction format and block
    authoring rules of the parachain, as well as having access to the full state
    of the parachain.
    \item Fishermen. These are user-operated, permissionless nodes whose goal is
    to catch misbehaving validators in exchange for a bounty. Collators and
    validators can behave as Fishermen too. Fishermen aren't necessary for
    security, and aren't covered in-depth by this document.
\end{enumerate}

This alludes to a simple pipeline where collators send validators parachain
blocks and their requisite PoV to check. Then, validators validate the block
using the PoV, signing statements which describe either the positive or negative
outcome, and with enough positive statements, the block can be noted on the
relay-chain. Negative statements are not a veto but will lead to a dispute, with
those on the wrong side being slashed. If another validator later detects that a
validator or group of validators incorrectly signed a statement claiming a block
was valid, then those validators will be slashed, with the checker receiving a
bounty.
\newline

However, there is a problem with this formulation. In order for another
validator to check the previous group of validators' work after the fact, the
PoV must remain available so the other validator can fetch it in order to check
the work. The PoVs are expected to be too large to include in the blockchain
directly, so we require an alternate data availability scheme which requires
validators to prove that the inputs to their work will remain available, and so
their work can be checked. Empirical tests tell us that many PoVs may be between
1 and 10MB during periods of heavy load.
\newline

Here is a description of the Inclusion Pipeline: the path a parachain block (or
parablock, for short) takes from creation to inclusion:
\newline

\begin{enumerate}
    \item Validators are selected and assigned to parachains by the Validator
    Assignment routine.
    \item A collator produces the parachain block, which is known as a parachain
    candidate or candidate, along with a PoV for the candidate.
    \item The collator forwards the candidate and PoV to validators assigned to
    the same parachain via the Collation Distribution Subsystem.
    \item The validators assigned to a parachain at a given point in time
    participate in the Candidate Backing Subsystem to validate candidates that
    were put forward for validation. Candidates which gather enough signed
    validity statements from validators are considered "backable". Their backing
    is the set of signed validity statements.
    \item A relay-chain block author, selected by BABE, can note up to one (1)
    backable candidate for each parachain to include in the relay-chain block
    alongside its backing. A backable candidate once included in the relay-chain
    is considered backed in that fork of the relay-chain.
    \item Once backed in the relay-chain, the parachain candidate is considered
    to be "pending availability". It is not considered to be included as part of
    the parachain until it is proven available.
    \item In the following relay-chain blocks, validators will participate in
    the Availability Distribution Subsystem to ensure availability of the
    candidate. Information regarding the availability of the candidate will be
    noted in the subsequent relay-chain blocks.
    \item Once the relay-chain state machine has enough information to consider
    the candidate's PoV as being available, the candidate is considered to be
    part of the parachain and is graduated to being a full parachain block, or
    parablock for short.
\end{enumerate}

Note that the candidate can fail to be included in any of the following ways:

\begin{itemize}
    \item The collator is not able to propagate the candidate to any validators
    assigned to the parachain.
    \item The candidate is not backed by validators participating in the
    Candidate Backing Subsystem.
    \item The candidate is not selected by a relay-chain block author to be
    included in the relay chain.
    \item The candidate's PoV is not considered as available within a timeout
    and is discarded from the relay chain.
\end{itemize}

This process can be divided further down. Steps 2 \& 3 relate to the work of the
collator in collating and distributing the candidate to validators via the
Collation Distribution Subsystem. Steps 3 \& 4 relate to the work of the
validators in the Candidate Backing Subsystem and the block author (itself a
validator) to include the block into the relay chain. Steps 6, 7, and 8
correspond to the logic of the relay-chain state-machine (otherwise known as the
Runtime) used to fully incorporate the block into the chain. Step 7 requires
further work on the validators' parts to participate in the Availability
Distribution Subsystem and include that information into the relay chain for
step 8 to be fully realized.
\newline

This brings us to the second part of the process. Once a parablock is considered
available and part of the parachain, it is still "pending approval". At this
stage in the pipeline, the parablock has been backed by a majority of validators
in the group assigned to that parachain, and its data has been guaranteed
available by the set of validators as a whole. Once it's considered available,
the host will even begin to accept children of that block. At this point, we can
consider the parablock as having been tentatively included in the parachain,
although more confirmations are desired. However, the validators in the
parachain-group (known as the "Parachain Validators" for that parachain) are
sampled from a validator set which contains some proportion of byzantine, or
arbitrarily malicious members. This implies that the Parachain Validators for
some parachain may be majority-dishonest, which means that secondary checks must
be done on the block before it can be considered approved. This is necessary
only because the Parachain Validators for a given parachain are sampled from an
overall validator set which is assumed to be up to <1/3 dishonest - meaning that
there is a chance to randomly sample Parachain Validators for a parachain that
are majority or fully dishonest and can back a candidate wrongly. The Approval
Process allows us to detect such misbehavior after-the-fact without allocating
more Parachain Validators and reducing the throughput of the system. A
parablock's failure to pass the approval process will invalidate the block as
well as all of its descendents. However, only the validators who backed the
block in question will be slashed, not the validators who backed the
descendents.
\newline

The Approval Process looks like this:

\begin{enumerate}
    \item Parablocks that have been included by the Inclusion Pipeline are
    pending approval for a time-window known as the secondary checking window.
    \item During the secondary-checking window, validators randomly self-select
    to perform secondary checks on the parablock.
    \item These validators, known in this context as secondary checkers, acquire
    the parablock and its PoV, and re-run the validation function.
    \item The secondary checkers submit the result of their checks to the relay
    chain. Contradictory results lead to escalation, where even more secondary
    checkers are selected and the secondary-checking window is extended.
    \item At the end of the Approval Process, the parablock is either Approved
    or it is rejected. More on the rejection process later.
\end{enumerate}

These two pipelines sum up the sequence of events necessary to extend and
acquire full security on a Parablock. Note that the Inclusion Pipeline must
conclude for a specific parachain before a new block can be accepted on that
parachain. After inclusion, the Approval Process kicks off, and can be running
for many parachain blocks at once.
\newline

Reiterating the lifecycle of a candidate:

\begin{enumerate}
    \item Candidate: put forward by a collator to a validator.
    \item Seconded: put forward by a validator to other validators.
    \item Backable: validity attested to by a majority of assigned validators.
    \item Backed: Backable \& noted in a fork of the relay-chain.
    \item Pending availability: Backed but not yet considered available.
    \item Included: Backed and considered available.
    \item Accepted: Backed, available, and undisputed
\end{enumerate}

\todo{Diagram: Inclusion Pipeline \& Approval Subsystems interaction}

It is also important to take note of the fact that the relay-chain is extended
by BABE, which is a forkful algorithm. That means that different block authors
can be chosen at the same time, and may not be building on the same block
parent. Furthermore, the set of validators is not fixed, nor is the set of
parachains. And even with the same set of validators and parachains, the
validators' assignments to parachains is flexible. This means that the
architecture proposed in the next chapters must deal with the variability and
multiplicity of the network state.

\begin{verbnobox}[\small]
....... Validator Group 1 ..........
.                                  .
.         (Validator 4)            .
.  (Validator 1) (Validator 2)     .
.         (Validator 5)            .
.                                  .
..........Building on C  ...........        ........ Validator Group 2 ...........
        +----------------------+           .                                    .
        |    Relay Block C     |           .           (Validator 7)            .
        +----------------------+           .    ( Validator 3) (Validator 6)    .
                        \                  .                                    .
                         \                 ......... Building on B  .............
                          \
                    +----------------------+
                    |  Relay Block B       |
                    +----------------------+
                                |
                    +----------------------+
                    |  Relay Block A       |
                    +----------------------+
\end{verbnobox}

In this example, group 1 has received block C while the others have not due to
network asynchrony. Now, a validator from group 2 may be able to build another
block on top of B, called C'. Assume that afterwards, some validators become
aware of both C and C', while others remain only aware of one.

\begin{verbnobox}[\small]
....... Validator Group 1 ..........      ........ Validator Group 2 ...........
.                                  .      .                                    .
.  (Validator 4) (Validator 1)     .      .    (Validator 7) (Validator 6)     .
.                                  .      .                                    .
.......... Building on C  ..........      ......... Building on C' .............


....... Validator Group 3 ..........
.                                  .
.   (Validator 2) (Validator 3)    .
.        (Validator 5)             .
.                                  .
....... Building on C and C' .......

        +----------------------+         +----------------------+
        |    Relay Block C     |         |    Relay Block C'    |
        +----------------------+         +----------------------+
                         \                 /
                          \               /
                           \             /
                    +----------------------+
                    |  Relay Block B       |
                    +----------------------+
                                |
                    +----------------------+
                    |  Relay Block A       |
                    +----------------------+
\end{verbnobox}

\textbf{Those validators that are aware of many competing heads must be aware of the
work happening on each one. They may contribute to some or a full extent on
both. It is possible that due to network asynchrony two forks may grow in
parallel for some time, although in the absence of an adversarial network this
is unlikely in the case where there are validators who are aware of both chain
heads.}

\section{Architecture}

Our Parachain Host includes a blockchain known as the relay-chain. A blockchain
is a Directed Acyclic Graph (DAG) of state transitions, where every block can be
considered to be the head of a linked-list (known as a "chain" or "fork") with a
cumulative state which is determined by applying the state transition of each
block in turn. All paths through the DAG terminate at the Genesis Block. In
fact, the blockchain is a tree, since each block can have only one parent.

\begin{verbnobox}[\small]
+----------------+     +----------------+
|    Block 4     |     | Block 5        |
+----------------+     +----------------+
               \           /
                V         V
            +---------------+
            |    Block 3    |
            +---------------+
                    |
                    V
            +----------------+     +----------------+
            |    Block 1     |     |   Block 2      |
            +----------------+     +----------------+
                       \            /
                        V          V
                    +----------------+
                    |    Genesis     |
                    +----------------+
\end{verbnobox}

A blockchain network is comprised of nodes. These nodes each have a view of many
different forks of a blockchain and must decide which forks to follow and what
actions to take based on the forks of the chain that they are aware of.
\newline

So in specifying an architecture to carry out the functionality of a Parachain
Host, we have to answer two categories of questions:

\begin{enumerate}
    \item What is the state-transition function of the blockchain? What is
    necessary for a transition to be considered valid, and what information is
    carried within the implicit state of a block?
    \item Being aware of various forks of the blockchain as well as global
    private state such as a view of the current time, what behaviors should a
    node undertake? What information should a node extract from the state of
    which forks, and how should that information be used?
\end{enumerate}

The first category of questions will be addressed by the Runtime, which defines
the state-transition logic of the chain. Runtime logic only has to focus on the
perspective of one chain, as each state has only a single parent state.
\newline

The second category of questions addressed by Node-side behavior. Node-side
behavior defines all activities that a node undertakes, given its view of the
blockchain/block-DAG. Node-side behavior can take into account all or many of
the forks of the blockchain, and only conditionally undertake certain activities
based on which forks it is aware of, as well as the state of the head of those
forks.

\begin{verbnobox}[\small]
     __________________________________
    /                                  \
    |            Runtime               |
    |                                  |
    \_________(Runtime API )___________/
                |       ^
                V       |
+----------------------------------------------+
|                                              |
|                   Node                       |
|                                              |
|                                              |
+----------------------------------------------+
                    +  +
                    |  |
--------------------+  +------------------------
                    Transport
------------------------------------------------
\end{verbnobox}

It is also helpful to divide Node-side behavior into two further categories:
Networking and Core. Networking behaviors relate to how information is
distributed between nodes. Core behaviors relate to internal work that a
specific node does. These two categories of behavior often interact, but can be
heavily abstracted from each other. Core behaviors care that information is
distributed and received, but not the internal details of how distribution and
receipt function. Networking behaviors act on requests for distribution or
fetching of information, but are not concerned with how the information is used
afterwards. This allows us to create clean boundaries between Core and
Networking activities, improving the modularity of the code.

\begin{verbnobox}
 ___________________                    ____________________
/       Core        \                  /     Networking     \
|                   |  Send "Hello"    |                    |
|                   |-  to "foo"   --->|                    |
|                   |                  |                    |
|                   |                  |                    |
|                   |                  |                    |
|                   |    Got "World"   |                    |
|                   |<--  from "bar" --|                    |
|                   |                  |                    |
\___________________/                  \____________________/
                                        ______| |______
                                        ___Transport___
\end{verbnobox}

Node-side behavior is split up into various subsystems. Subsystems are
long-lived workers that perform a particular category of work. Subsystems can
communicate with each other, and do so via an Overseer that prevents race
conditions.
\newline

Runtime logic is divided up into Modules and APIs. Modules encapsulate
particular behavior of the system. Modules consist of storage, routines, and
entry-points. Routines are invoked by entry points, by other modules, upon block
initialization or closing. Routines can read and alter the storage of the
module. Entry-points are the means by which new information is introduced to a
module and can limit the origins (user, root, parachain) that they accept being
called by. Each block in the blockchain contains a set of Extrinsics. Each
extrinsic targets a a specific entry point to trigger and which data should be
passed to it. Runtime APIs provide a means for Node-side behavior to extract
meaningful information from the state of a single fork.
\newline

These two aspects of the implementation are heavily dependent on each other. The
Runtime depends on Node-side behavior to author blocks, and to include
Extrinsics which trigger the correct entry points. The Node-side behavior relies
on Runtime APIs to extract information necessary to determine which actions to
take.

\section{Architecture: Runtime}

\subsection{Broad Strokes}

It's clear that we want to separate different aspects of the runtime logic into
different modules. Modules define their own storage, routines, and entry-points.
They also define initialization and finalization logic.
\newline

Due to the (lack of) guarantees provided by a particular blockchain-runtime
framework, there is no defined or dependable order in which modules'
initialization or finalization logic will run. Supporting this
blockchain-runtime framework is important enough to include that same
uncertainty in our model of runtime modules in this guide. Furthermore,
initialization logic of modules can trigger the entry-points or routines of
other modules. This is one architectural pressure against dividing the runtime
logic into multiple modules. However, in this case the benefits of splitting
things up outweigh the costs, provided that we take certain precautions against
initialization and entry-point races.
\newline

We also expect, although it's beyond the scope of this guide, that these runtime
modules will exist alongside various other modules. This has two facets to
consider. First, even if the modules that we describe here don't invoke each
others' entry points or routines during initialization, we still have to protect
against those other modules doing that. Second, some of those modules are
expected to provide governance capabilities for the chain. Configuration exposed
by parachain-host modules is mostly for the benefit of these governance modules,
to allow the operators or community of the chain to tweak parameters.
\newline

The runtime's primary roles to manage scheduling and updating of parachains and
parathreads, as well as handling misbehavior reports and slashing. This guide
doesn't focus on how parachains or parathreads are registered, only that they
are. Also, this runtime description assumes that validator sets are selected
somehow, but doesn't assume any other details than a periodic session change
event. Session changes give information about the incoming validator set and the
validator set of the following session.
\newline

The runtime also serves another role, which is to make data available to the
Node-side logic via Runtime APIs. These Runtime APIs should be sufficient for
the Node-side code to author blocks correctly.
\newline

There is some functionality of the relay chain relating to parachains that we
also consider beyond the scope of this document. In particular, all modules
related to how parachains are registered aren't part of this guide, although we
do provide routines that should be called by the registration process.
\newline

We will split the logic of the runtime up into these modules:

\begin{itemize}
    \item Initializer: manage initialization order of the other modules.
    \item Configuration: manage configuration and configuration updates in a
    non-racy manner.
    \item Paras: manage chain-head and validation code for parachains and
    parathreads.
    \item Scheduler: manages parachain and parathread scheduling as well as
    validator assignments.
    \item Inclusion: handles the inclusion and availability of scheduled
    parachains and parathreads.
    \item Validity: handles secondary checks and dispute resolution for
    included, available parablocks.
\end{itemize}

The Initializer module is special - it's responsible for handling the
initialization logic of the other modules to ensure that the correct
initialization order and related invariants are maintained. The other modules
won't specify a on-initialize logic, but will instead expose a special
semi-private routine that the initialization module will call. The other modules
are relatively straightforward and perform the roles described above.
\newline

The Parachain Host operates under a changing set of validators. Time is split up
into periodic sessions, where each session brings a potentially new set of
validators. Sessions are buffered by one, meaning that the validators of the
upcoming session are fixed and always known. Parachain Host runtime modules need
to react to changes in the validator set, as it will affect the runtime logic
for processing candidate backing, availability bitfields, and misbehavior
reports. The Parachain Host modules can't determine ahead-of-time exactly when
session change notifications are going to happen within the block (note: this
depends on module initialization order again - better to put session before
parachains modules). Ideally, session changes are always handled before
initialization. It is clearly a problem if we compute validator assignments to
parachains during initialization and then the set of validators changes. In the
best case, we can recognize that re-initialization needs to be done. In the
worst case, bugs would occur.
\newline

There are 3 main ways that we can handle this issue:

\begin{enumerate}
    \item Establish an invariant that session change notifications always happen
    after initialization. This means that when we receive a session change
    notification before initialization, we call the initialization routines
    before handling the session change.
    \item Require that session change notifications always occur before
    initialization. Brick the chain if session change notifications ever happen
    after initialization.
    \item Handle both the before and after cases.
\end{enumerate}

Although option 3 is the most comprehensive, it runs counter to our goal of
simplicity. Option 1 means requiring the runtime to do redundant work at all
sessions and will also mean, like option 3, that designing things in such a way
that initialization can be rolled back and reapplied under the new environment.
That leaves option 2, although it is a "nuclear" option in a way and requires us
to constrain the parachain host to only run in full runtimes with a certain
order of operations.
\newline

So the other role of the initializer module is to forward session change
notifications to modules in the initialization order, throwing an unrecoverable
error if the notification is received after initialization. Session change is
the point at which the configuration module updates the configuration. Most of
the other modules will handle changes in the configuration during their session
change operation, so the initializer should provide both the old and new
configuration to all the other modules alongside the session change
notification. This means that a session change notification should consist of
the following data:

\begin{verbnobox}[\small]
struct SessionChangeNotification {
	// The new validators in the session.
	validators: Vec<ValidatorId>,
	// The validators for the next session.
	queued: Vec<ValidatorId>,
	// The configuration before handling the session change.
	prev_config: HostConfiguration,
	// The configuration after handling the session change.
	new_config: HostConfiguration,
	// A secure randomn seed for the session, gathered from BABE.
	random_seed: [u8; 32],
}
\end{verbnobox}

\todo{REVIEW: other options? arguments in favor of going for options 1 or 3 instead of
2. we could do a "soft" version of 2 where we note that the chain is potentially
broken due to bad initialization order}
\newline

\todo{Diagram: order of runtime operations (initialization, session change)}

\subsection{The Initializer Module}

\subsubsection{Description}

This module is responsible for initializing the other modules in a deterministic
order. It also has one other purpose as described above: accepting and
forwarding session change notifications.

\subsubsection{Storage}

\begin{verbnobox}[\small] HasInitialized: bool
\end{verbnobox}

\subsubsection{Initialization}

The other modules are initialized in this order:

\begin{enumerate}
    \item Configuration
    \item Paras
    \item Scheduler
    \item Inclusion
    \item Validity
\end{enumerate}

The configuration module is first, since all other modules need to operate under
the same configuration as each other. It would lead to inconsistency if, for
example, the scheduler ran first and then the configuration was updated before
the Inclusion module.
\newline

Set \verb|HasInitialized| to true.

\subsubsection{Session Change}

If \verb|HasInitialized| is true, throw an unrecoverable error (panic).
Otherwise, forward the session change notification to other modules in
initialization order.

\subsubsection{Finalization}

Finalization order is less important in this case than initialization order, so
we finalize the modules in the reverse order from initialization.
\newline

Set \verb|HasInitialized| to false.

\subsection{The Configuration Module}

\subsubsection{Description}

This module is responsible for managing all configuration of the parachain host
in-flight. It provides a central point for configuration updates to prevent
races between configuration changes and parachain-processing logic.
Configuration can only change during the session change routine, and as this
module handles the session change notification first it provides an invariant
that the configuration does not change throughout the entire session. Both the
scheduler and inclusion modules rely on this invariant to ensure proper behavior
of the scheduler.
\newline

The configuration that we will be tracking is the \verb|HostConfiguration|
struct. \todo{@lamafab: link to type}

\subsubsection{Storage}

The configuration module is responsible for two main pieces of storage.

\begin{verbnobox}[\small]
/// The current configuration to be used.
Configuration: HostConfiguration;
/// A pending configuration to be applied on session change.
PendingConfiguration: Option<HostConfiguration>;
\end{verbnobox}

\subsubsection{Session change}

The session change routine for the Configuration module is simple. If the
\verb|PendingConfiguration| is \verb|Some|, take its value and set
\verb|Configuration| to be equal to it. Reset \verb|PendingConfiguration| to
\verb|None|.

\subsubsection{Routines}

\begin{verbnobox}[\small]
/// Get the host configuration.
pub fn configuration() -> HostConfiguration {
  Configuration::get()
}

/// Updating the pending configuration to be applied later.
fn update_configuration(f: impl FnOnce(&mut HostConfiguration)) {
  PendingConfiguration::mutate(|pending| {
    let mut x = pending.unwrap_or_else(Self::configuration);
    f(&mut x);
    *pending = Some(x);
  })
}
\end{verbnobox}

\subsubsection{Entry-points}

The Configuration module exposes an entry point for each configuration member.
These entry-points accept calls only from governance origins. These entry-points
will use the \verb|update_configuration| routine to update the specific
configuration field.

\subsection{The Paras Module}

\subsubsection{Description}

The Paras module is responsible for storing information on parachains and
parathreads. Registered parachains and parathreads cannot change except at
session boundaries. This is primarily to ensure that the number of bits required
for the availability bitfields does not change except at session boundaries.
\newline

It's also responsible for managing parachain validation code upgrades as well as
maintaining availability of old parachain code and its pruning.

\subsubsection{Storage}

Utility structs:

\begin{verbnobox}[\small]
// the two key times necessary to track for every code replacement.
pub struct ReplacementTimes {
	/// The relay-chain block number that the code upgrade was expected to be activated.
	/// This is when the code change occurs from the para's perspective - after the
	/// first parablock included with a relay-parent with number >= this value.
	expected_at: BlockNumber,
	/// The relay-chain block number at which the parablock activating the code upgrade was
	/// actually included. This means considered included and available, so this is the time at which
	/// that parablock enters the acceptance period in this fork of the relay-chain.
	activated_at: BlockNumber,
}

/// Metadata used to track previous parachain validation code that we keep in
/// the state.
pub struct ParaPastCodeMeta {
	// Block numbers where the code was expected to be replaced and where the code
	// was actually replaced, respectively. The first is used to do accurate lookups
	// of historic code in historic contexts, whereas the second is used to do
	// pruning on an accurate timeframe. These can be used as indices
	// into the `PastCode` map along with the `ParaId` to fetch the code itself.
	upgrade_times: Vec<ReplacementTimes>,
	// This tracks the highest pruned code-replacement, if any.
	last_pruned: Option<BlockNumber>,
}

enum UseCodeAt {
	// Use the current code.
	Current,
	// Use the code that was replaced at the given block number.
	ReplacedAt(BlockNumber),
}

struct ParaGenesisArgs {
  /// The initial head-data to use.
  genesis_head: HeadData,
  /// The validation code to start with.
  validation_code: ValidationCode,
  /// True if parachain, false if parathread.
  parachain: bool,
}
\end{verbnobox}

Storage layout:

\begin{verbnobox}[\small]
/// All parachains. Ordered ascending by ParaId. Parathreads are not included.
Parachains: Vec<ParaId>,
/// The head-data of every registered para.
Heads: map ParaId => Option<HeadData>;
/// The validation code of every live para.
ValidationCode: map ParaId => Option<ValidationCode>;
/// Actual past code, indicated by the para id as well as the block number at which it became outdated.
PastCode: map (ParaId, BlockNumber) => Option<ValidationCode>;
/// Past code of parachains. The parachains themselves may not be registered anymore,
/// but we also keep their code on-chain for the same amount of time as outdated code
/// to keep it available for secondary checkers.
PastCodeMeta: map ParaId => ParaPastCodeMeta;
/// Which paras have past code that needs pruning and the relay-chain block at which the code was replaced.
/// Note that this is the actual height of the included block, not the expected height at which the
/// code upgrade would be applied, although they may be equal.
/// This is to ensure the entire acceptance period is covered, not an offset acceptance period starting
/// from the time at which the parachain perceives a code upgrade as having occurred.
/// Multiple entries for a single para are permitted. Ordered ascending by block number.
PastCodePruning: Vec<(ParaId, BlockNumber)>;
/// The block number at which the planned code change is expected for a para.
/// The change will be applied after the first parablock for this ID included which executes
/// in the context of a relay chain block with a number >= `expected_at`.
FutureCodeUpgrades: map ParaId => Option<BlockNumber>;
/// The actual future code of a para.
FutureCode: map ParaId => Option<ValidationCode>;

/// Upcoming paras (chains and threads). These are only updated on session change. Corresponds to an
/// entry in the upcoming-genesis map.
UpcomingParas: Vec<ParaId>;
/// Upcoming paras instantiation arguments.
UpcomingParasGenesis: map ParaId => Option<ParaGenesisArgs>;
/// Paras that are to be cleaned up at the end of the session.
OutgoingParas: Vec<ParaId>;
\end{verbnobox}

\subsubsection{Session Change}

\begin{enumerate}
    \item Clean up outgoing paras. This means removing the entries under
    \verb|Heads|, \verb|ValidationCode|, \verb|FutureCodeUpgrades|, and
    \verb|FutureCode|. An according entry should be added to \verb|PastCode|,
    \verb|PastCodeMeta|, and \verb|PastCodePruning| using the outgoing
    \verb|ParaId| and removed \verb|ValidationCode| value. This is because any
    outdated validation code must remain available on-chain for a determined
    amount of blocks, and validation code outdated by de-registering the para is
    still subject to that invariant.
    \item Apply all incoming paras by initializing the \verb|Heads| and
    \verb|ValidationCode| using the genesis parameters.
    \item Amend the Parachains list to reflect changes in registered parachains.
\end{enumerate}

\subsubsection{Initialization}

\begin{enumerate}
    \item Do pruning based on all entries in \verb|PastCodePruning| with
    \verb|BlockNumber <= now|. Update the corresponding \verb|PastCodeMeta| and
    \verb|PastCode| accordingly.
\end{enumerate}

\subsubsection{Routines}

\begin{itemize}
    \item \verb|schedule_para_initialize(ParaId, ParaGenesisArgs)|: schedule a
    para to be initialized at the next session.
    \item \verb|schedule_para_cleanup(ParaId)|: schedule a para to be cleaned up
    at the next session.
    \item \verb|schedule_code_upgrade(ParaId, ValidationCode, expected_at: BlockNumber)|:
    Schedule a future code upgrade of the given parachain, to be
    applied after inclusion of a block of the same parachain executed in the
    context of a relay-chain block with number $\leq$ \verb|expected_at|.
    \item \verb|note_new_head(ParaId, HeadData, BlockNumber)|: note that a para
    has progressed to a new head, where the new head was executed in the context
    of a relay-chain block with given number. This will apply pending code
    upgrades based on the block number provided.
    \item \verb|validation_code_at(ParaId, at: BlockNumber, assume_intermediate:|
    \newline
    \verb|Option<BlockNumber>)|:
    Fetches the validation code to be used when
    validating a block in the context of the given relay-chain height. A second
    block number parameter may be used to tell the lookup to proceed as if an
    intermediate parablock has been included at the given relay-chain height.
    This may return past, current, or (with certain choices of
    \verb|assume_intermediate|) future code. \verb|assume_intermediate|, if
    provided, must be before \verb|at|. If the validation code has been pruned,
    this will return \verb|None|.
\end{itemize}

\subsubsection{Finalization}

No finalization routine runs for this module.

\subsection{The Scheduler Module}

\subsubsection{Description}

\todo{this section is still heavily under construction. key questions about
availability cores and validator assignment are still open and the flow of the
the section may be contradictory or inconsistent.}
\newline

The Scheduler module is responsible for two main tasks:

\begin{itemize}
    \item Partitioning validators into groups and assigning groups to parachains
    and parathreads.
    \item Scheduling parachains and parathreads
\end{itemize}

It aims to achieve these tasks with these goals in mind:

\begin{itemize}
    \item It should be possible to know at least a block ahead-of-time, ideally
    more, which validators are going to be assigned to which parachains.
    \item Parachains that have a candidate pending availability in this fork of
    the chain should not be assigned.
    \item Validator assignments should not be gameable. Malicious cartels should
    not be able to manipulate the scheduler to assign themselves as desired.
    \item High or close to optimal throughput of parachains and parathreads.
    Work among validator groups should be balanced.
\end{itemize}

The Scheduler manages resource allocation using the concept of "Availability
Cores". There will be one availability core for each parachain, and a fixed
number of cores used for multiplexing parathreads. Validators will be
partitioned into groups, with the same number of groups as availability cores.
Validator groups will be assigned to different availability cores over time.
\newline

An availability core can exist in either one of two states at the beginning or
end of a block: free or occupied. A free availability core can have a parachain
or parathread assigned to it for the potential to have a backed candidate
included. After inclusion, the core enters the occupied state as the backed
candidate is pending availability. There is an important distinction: a core is
not considered occupied until it is in charge of a block pending availability,
although the implementation may treat scheduled cores the same as occupied ones
for brevity. A core exits the occupied state when the candidate is no longer
pending availability - either on timeout or on availability. A core starting in
the occupied state can move to the free state and back to occupied all within a
single block, as availability bitfields are processed before backed candidates.
At the end of the block, there is a possible timeout on availability which can
move the core back to the free state if occupied.

\begin{verbnobox}[\small]
Availability Core State Machine
              Assignment &
              Backing
+-----------+              +-----------+
|           +-------------->           |
|  Free     |              | Occupied  |
|           <--------------+           |
+-----------+ Availability +-----------+
              or Timeout
\end{verbnobox}

\begin{verbnobox}[\small]
Availability Core Transitions within Block

              +-----------+                |                    +-----------+
              |           |                |                    |           |
              | Free      |                |                    | Occupied  |
              |           |                |                    |           |
              +--/-----\--+                |                    +--/-----\--+
               /-       -\                 |                     /-       -\
 No Backing  /-           \ Backing        |      Availability /-           \ No availability
           /-              \               |                  /              \
         /-                 -\             |                /-                -\
  +-----v-----+         +----v------+      |         +-----v-----+        +-----v-----+
  |           |         |           |      |         |           |        |           |
  | Free      |         | Occupied  |      |         | Free      |        | Occupied  |
  |           |         |           |      |         |           |        |           |
  +-----------+         +-----------+      |         +-----|---\-+        +-----|-----+
                                           |               |    \               |
                                           |    No backing |     \ Backing      | (no change)
                                           |               |     -\             |
                                           |         +-----v-----+ \      +-----v-----+
                                           |         |           |  \     |           |
                                           |         | Free      -----+---> Occupied  |
                                           |         |           |        |           |
                                           |         +-----------+        +-----------+
                                           |                 Availability Timeout
\end{verbnobox}

Validator group assignments do not need to change very quickly. The security
benefits of fast rotation is redundant with the challenge mechanism in the
Validity module. Because of this, we only divide validators into groups at the
beginning of the session and do not shuffle membership during the session.
However, we do take steps to ensure that no particular validator group has
dominance over a single parachain or parathread-multiplexer for an entire
session to provide better guarantees of liveness.
\newline

Validator groups rotate across availability cores in a round-robin fashion, with
rotation occurring at fixed intervals. The i'th group will be assigned to the
(i+k)\%n'th core at any point in time, where k is the number of rotations that
have occurred in the session, and n is the number of cores. This makes upcoming
rotations within the same session predictable.
\todo{@lamafab: adjust math}
\newline

When a rotation occurs, validator groups are still responsible for distributing
availability pieces for any previous cores that are still occupied and pending
availability. In practice, rotation and availability-timeout frequencies should
be set so this will only be the core they have just been rotated from. It is
possible that a validator group is rotated onto a core which is currently
occupied. In this case, the validator group will have nothing to do until the
previously-assigned group finishes their availability work and frees the core or
the availability process times out. Depending on if the core is for a parachain
or parathread, a different timeout \verb|t| from the \verb|HostConfiguration| will apply.
Availability timeouts should only be triggered in the first $t-1$ blocks after the
beginning of a rotation.
\newline

Parathreads operate on a system of claims. Collators participate in auctions to
stake a claim on authoring the next block of a parathread, although the auction
mechanism is beyond the scope of the scheduler. The scheduler guarantees that
they'll be given at least a certain number of attempts to author a candidate
that is backed. Attempts that fail during the availability phase are not
counted, since ensuring availability at that stage is the responsibility of the
backing validators, not of the collator. When a claim is accepted, it is placed
into a queue of claims, and each claim is assigned to a particular
parathread-multiplexing core in advance. Given that the current assignments of
validator groups to cores are known, and the upcoming assignments are
predictable, it is possible for parathread collators to know who they should be
talking to now and how they should begin establishing connections with as a
fallback.
\newline

With this information, the Node-side can be aware of which parathreads have a
good chance of being includable within the relay-chain block and can focus any
additional resources on backing candidates from those parathreads. Furthermore,
Node-side code is aware of which validator group will be responsible for that
thread. If the necessary conditions are reached for core reassignment, those
candidates can be backed within the same block as the core being freed.
\newline

Parathread claims, when scheduled onto a free core, may not result in a block
pending availability. This may be due to collator error, networking timeout, or
censorship by the validator group. In this case, the claims should be retried a
certain number of times to give the collator a fair shot.
\newline

Cores are treated as an ordered list of cores and are typically referred to by
their index in that list.

\subsubsection{Storage}

Utility structs:

\begin{verbnobox}[\small]
// A claim on authoring the next block for a given parathread.
struct ParathreadClaim(ParaId, CollatorId);

// An entry tracking a claim to ensure it does not pass the maximum number of retries.
struct ParathreadEntry {
  claim: ParathreadClaim,
  retries: u32,
}

// A queued parathread entry, pre-assigned to a core.
struct QueuedParathread {
	claim: ParathreadEntry,
	core: CoreIndex,
}

struct ParathreadQueue {
	queue: Vec<QueuedParathread>,
	// this value is between 0 and config.parathread_cores
	next_core: CoreIndex,
}

enum CoreOccupied {
  Parathread(ParathreadEntry), // claim & retries
  Parachain,
}

struct CoreAssignment {
  core: CoreIndex,
  para_id: ParaId,
  collator: Option<CollatorId>,
  group_idx: GroupIndex,
}
\end{verbnobox}

Storage layout:

\begin{verbnobox}[\small]
/// All the validator groups. One for each core.
ValidatorGroups: Vec<Vec<ValidatorIndex>>;
/// A queue of upcoming claims and which core they should be mapped onto.
ParathreadQueue: ParathreadQueue;
/// One entry for each availability core. Entries are `None` if the core is not currently occupied. Can be
/// temporarily `Some` if scheduled but not occupied.
/// The i'th parachain belongs to the i'th core, with the remaining cores all being
/// parathread-multiplexers.
AvailabilityCores: Vec<Option<CoreOccupied>>;
/// An index used to ensure that only one claim on a parathread exists in the queue or is
/// currently being handled by an occupied core.
ParathreadClaimIndex: Vec<ParaId>;
/// The block number where the session start occurred. Used to track how many group rotations have occurred.
SessionStartBlock: BlockNumber;
/// Currently scheduled cores - free but up to be occupied. Ephemeral storage item that's wiped on finalization.
Scheduled: Vec<CoreAssignment>, // sorted ascending by CoreIndex.
\end{verbnobox}

\subsubsection{Session Change}

Session changes are the only time that configuration can change, and the
configuration module's session-change logic is handled before this module's. We
also lean on the behavior of the inclusion module which clears all its occupied
cores on session change. Thus we don't have to worry about cores being occupied
across session boundaries and it is safe to re-size the \verb|AvailabilityCores|
bitfield.
\newline

Actions:

\todo{@lamafab: adjust subitems}

\begin{enumerate}
    \item Set \verb|SessionStartBlock| to current block number.
    \item Clear all \verb|Some| members of \verb|AvailabilityCores|. Return all
    parathread claims to queue with retries un-incremented.
    \item Set \verb|configuration = Configuration::configuration()| (see HostConfiguration) \todo{@lamafab: set link}
    \item Resize \verb|AvailabilityCores| to have length
    \verb|Paras::parachains().len() +|
    \newline
    \verb|configuration.parathread_cores with all None| entries.
    \item Compute new validator groups by shuffling using a secure randomness
    beacon.
    \item We need a total of \verb|N = Paras::parathreads().len() +|
    \verb|configuration.parathread_cores| validator groups.
    \item The total number of validators \verb|V| in the \verb|SessionChangeNotification|'s
    \verb|validators| may not be evenly divided by \verb|V|.
    \item First, we obtain
    "shuffled validators" \verb|SV| by shuffling the validators using the
    \verb|SessionChangeNotification|'s random seed.
    \item The groups are selected
    by partitioning \verb|SV|. The first V \% N groups will have (V / N) + 1 members,
    while the remaining groups will have (V / N) members each. \todo{@lamafab: adjust math}
    \item Prune the parathread queue to remove all retries beyond
    \verb|configuration.parathread_retries.|
    \item All pruned claims should have
    their entry removed from the parathread index.
    \item Assign all
    non-pruned claims to new cores if the number of parathread cores has changed
    between the \verb|new_config| and \verb|old_config| of the \verb|SessionChangeNotification|.
    \item Assign claims in equal balance across all cores if rebalancing, and
    set the \verb|next_core| of the \verb|ParathreadQueue| by incrementing the relative index
    of the last assigned core and taking it modulo the number of parathread
    cores.
\end{enumerate}

\subsubsection{Initialization}

\begin{enumerate}
    \item Schedule free cores using the \verb|schedule(Vec::new())|.
\end{enumerate}

\subsubsection{Finalization}

Actions:

\begin{enumerate}
    \item Free all scheduled cores and return parathread claims to queue, with
    retries incremented.
\end{enumerate}

\subsubsection{Routines}

\todo{@lamafab: adjust subitems}

\begin{itemize}
    \item \verb|add_parathread_claim(ParathreadClaim)|: Add a parathread claim to the
    queue.
    \item Fails if any parathread claim on the same parathread is
    currently indexed.
    \item Fails if the queue length is >=
    \verb|config.scheduling_lookahead * config.parathread_cores|.
    \item The core
    used for the parathread claim is the \verb|next_core| field of the \verb|ParathreadQueue|
    and adding \verb|Paras::parachains().len()| to it.
    \item \verb|next_core| is then
    updated by adding 1 and taking it modulo \verb|config.parathread_cores|.
    \item The claim is then added to the claim index.
    \item \verb|schedule(Vec<CoreIndex>)|: schedule new core assignments, with a
    parameter indicating previously-occupied cores which are to be considered
    returned.
    \item All freed parachain cores should be assigned to their
    respective parachain
    \item All freed parathread cores should have the
    claim removed from the claim index.
    \item All freed parathread cores
    should take the next parathread entry from the queue.
    \item The i'th
    validator group will be assigned to the (i+k)\%n'th core at any point in
    time, where \verb|k| is the number of rotations that have occurred in the session,
    and \verb|n| is the total number of cores. This makes upcoming rotations within the
    same session predictable. \todo{@lamafab: adjust math}
    \item scheduled() -> Vec<CoreAssignment>: Get currently scheduled core
    assignments.
    \item occupied(Vec). Note that the given cores have become occupied.
    \item Fails if any given cores were not scheduled.
    \item Fails if the
    given cores are not sorted ascending by core index.
    \item This clears
    them from Scheduled and marks each corresponding core in the
    AvailabilityCores as occupied.
    \item Since both the availability cores
    and the newly-occupied cores lists are sorted ascending, this method can be
    implemented efficiently.
    \item \verb|core_para(CoreIndex) -> ParaId|: return the currently-scheduled or
    occupied ParaId for the given core.
    \item \verb|group_validators(GroupIndex) -> Option<Vec<ValidatorIndex>>|: return
    all validators in a given group, if the group index is valid for this
    session.
    \item \verb|availability_timeout_predicate() -> Option<impl Fn(CoreIndex,|
    \verb|BlockNumber) -> bool>|: returns an optional predicate that should be used for
    timing out occupied cores. If \verb|None|, no timing-out should be done. The
    predicate accepts the index of the core, and the block number since which it
    has been occupied. The predicate should be implemented based on the time
    since the last validator group rotation, and the respective parachain and
    parathread timeouts, i.e. only within \verb|max(config.chain_availability_period,|
    \newline
    \verb|config.thread_availability_period)| of the last rotation would this return
    \verb|Some|.
\end{itemize}

\subsection{The Inclusion Module}

\subsubsection{Description}

The inclusion module is responsible for inclusion and availability of scheduled
parachains and parathreads.

\subsubsection{Storage}

Helper structs:

\begin{verbnobox}[\small]
struct AvailabilityBitfield {
  bitfield: BitVec, // one bit per core.
  submitted_at: BlockNumber, // for accounting, as meaning of bits may change over time.
}

struct CandidatePendingAvailability {
  core: CoreIndex, // availability core
  receipt: AbridgedCandidateReceipt,
  availability_votes: Bitfield, // one bit per validator.
  relay_parent_number: BlockNumber, // number of the relay-parent.
  backed_in_number: BlockNumber,
}
\end{verbnobox}

Storage Layout:

\begin{verbnobox}[\small]
/// The latest bitfield for each validator, referred to by index.
bitfields: map ValidatorIndex => AvailabilityBitfield;
/// Candidates pending availability.
PendingAvailability: map ParaId => CandidatePendingAvailability;
\end{verbnobox}

\todo{CandidateReceipt and AbridgedCandidateReceipt can contain code upgrades
which make them very large. the code entries should be split into a different
storage map with infrequent access patterns.}

\subsubsection{Session Change}

\begin{enumerate}
    \item Clear out all candidates pending availability.
    \item Clear out all validator bitfields.
\end{enumerate}

\subsubsection{Routines}

All failed checks should lead to an unrecoverable error making the block
invalid.

\begin{itemize}
    \item \verb|process_bitfields(Bitfields, core_lookup: Fn(CoreIndex) -> Option<ParaId>)|:
    \begin{enumerate}
        \item Check that the number of bitfields and bits in each bitfield is correct.
        \item Check that there are no duplicates.
        \item Check all validator signatures.
        \item Apply each bit of bitfield to the corresponding pending candidate.
        looking up parathread cores using the \verb|core_lookup|. Disregard
        bitfields that have a \verb|1| bit for any free cores.
        \item For each applied bit of each availability-bitfield, set the bit
        for the validator in the \verb|CandidatePendingAvailability|'s
        \verb|availability_votes| bitfield. Track all candidates that now have
        $>2\div3$ of bits set in their \verb|availability_votes|. These candidates
        are now available and can be enacted.
        \item For all now-available candidates, invoke the
        \verb|enact_candidate| routine with the candidate and relay-parent
        number.
        \item \todo{pass it onwards to Validity module.}
        \item Return a list of freed cores consisting of the cores where
        candidates have become available.
    \end{enumerate}
    \item \verb|process_candidates(BackedCandidates, scheduled: Vec<CoreAssignment>)|:
    \begin{enumerate}
        \item Check that each candidate corresponds to a scheduled core and that
        they are ordered in ascending order by \verb|ParaId|.
        \item Ensure that any code upgrade scheduled by the candidate does not
        happen within \verb|config.validation_upgrade_frequency| of the currently
        scheduled upgrade, if any, comparing against the value of
        \verb|Paras::FutureCodeUpgrades| for the given para ID.
        \item Check the backing of the candidate using the signatures and the
        bitfields.
        \item create an entry in the \verb|PendingAvailability| map for each backed
        candidate with a blank \verb|availability_votes| bitfield.
        \item Return a \verb|Vec<CoreIndex>| of all scheduled cores of the list of
        passed assignments that a candidate was successfully backed for, sorted
        ascending by CoreIndex.
    \end{enumerate}
    \item \verb|enact_candidate(relay_parent_number: BlockNumber, AbridgedCandidateReceipt)|:
    \begin{enumerate}
        \item If the receipt contains a code upgrade, Call \verb|Paras::schedule_code_upgrade(para_id, code,|
        \verb|relay_parent_number + config.validationl_upgrade_delay)|.
        \todo{Note that this is safe as long
        as we never enact candidates where the relay parent is across a session
        boundary. In that case, which we should be careful to avoid with
        contextual execution, the configuration might have changed and the para
        may de-sync from the host's understanding of it.}
        \item Call \verb|Paras::note_new_head| using the \verb|HeadData| from the receipt and
        \verb|relay_parent_number|.
    \end{enumerate}
    \item \verb|collect_pending|
    \begin{verbnobox}[\small]
    fn collect_pending(f: impl Fn(CoreIndex, BlockNumber) -> bool) -> Vec<u32> {
      // sweep through all paras pending availability. if the predicate returns true, when given the core index and
      // the block number the candidate has been pending availability since, then clean up the corresponding storage for that candidate.
      // return a vector of cleaned-up core IDs.
    }
    \end{verbnobox}
\end{itemize}
